---
title: 4주차 과제_주제 선정 및 평가 크롤링 / 긍부정평가
create_date: 2024-06-20 12:06 - 2024-06-20 12:06
draft: true
description: 서울 신라 호텔 뷔페 더 파크뷰 리뷰 평가 긍/부정 평가 만들기 일지
---
>[!Todo]
>- [x] 1.데이터 수집
>- [ ] 2.데이터 전처리
>- [ ] 3.데이터 분석

---
## 1. 데이터 수집

- 서울 신라호텔 더 파크뷰에 대한 네이버 리뷰

- 리뷰를 얼마나 추출해야할까?
    - 200개에서 300개정도는 해야 어느 정도 윤곽이 잡히는 키워드들과 리뷰들에 대한 빅데이터를 가질 수 있다고 예상함

- 네이버 리뷰 링크를 주소로 사용하여 크롤링
    - 추출할 대상: 아이디, 리뷰 텍스트, 방문 날짜, 몇번째 방문

- 리뷰 텍스트가 전부 보이지 않는 경우가 있다.
    - 그 경우, 내용 더보기 버튼을 클릭하여 텍스트가 전부 다 보이게 한다.
    - for문을 돌려서 텍스트들을 추출할 때 try/except문을 써서 내용 더보기 버튼이 없는 리뷰에 예외처리를 해줘야한다.

- 페이지를 내렸을 때, 더보기 버튼을 눌러야 다른 리뷰 확인가능

### STEP 1. 순차적 개발

```python
# Setting
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.common.actions.action_builder import ActionBuilder
from selenium.webdriver.common.actions.mouse_button import MouseButton
from selenium.webdriver import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import pandas as pd

url = "https://pcmap.place.naver.com/restaurant/13166754/review/visitor"
```

```python
# 크롬창 열기
options = Options()
driver = webdriver.Chrome(options = options)

# 창모드 전체화면으로 크기 늘리기
driver.maximize_window()

# 로딩시간: 페이지 로딩
wait = WebDriverWait(driver, 10)
wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'body')))

# 네이버 리뷰 주소 접속하기
driver.get(url)

# 로딩시간: 페이지 로딩
wait = WebDriverWait(driver, 10)
wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'body')))
```

```python
# 데이터 받을 빈 딕셔너리
review_data = {"UserID":[],"Review_Text":[],"Date":[], "NumberOfVisit":[]}

# 리뷰 200개까지 나오게 미리 더보기 클릭하기
# for문 19번 돌리는 이유는 처음에 10개 있는 것을 빼고 세야함
print("총 리뷰 개수 구하기")
for num_reviews in range(19):
    driver.find_element(By.CLASS_NAME, 'fvwqf').click()
    time.sleep(1)
    
rows = driver.find_elements(By.CLASS_NAME, 'owAeM')


# rows의 개수를 세어 for문을 돌린다.
cnt = len(rows)
print("총 리뷰 개수: ", cnt)

# 리뷰 추출하기
log_count = 0
print("START", end = " >>> ")
for i in range(cnt):
	# 리뷰 내용 더보기 버튼이 없는 리뷰들 예외구문
    try:
        review_text_extend = rows[i].find_element(By.CLASS_NAME, 'Ky28p').click()
    except:
        pass

    user_id = rows[i].find_element(By.CLASS_NAME, 'qgLL3')
    review_text = rows[i].find_element(By.CLASS_NAME, 'zPfVt')
    number_visits = rows[i].find_elements(By.CLASS_NAME, 'CKUdu')[1]
    visit_date = rows[i].find_elements(By.CLASS_NAME, 'CKUdu')[0].find_elements(By.CLASS_NAME, 'place_blind')[1]

    review_data['UserID'].append(user_id.text)
    review_data['Review_Text'].append(review_text.text)
    review_data['Date'].append(visit_date.text)
    review_data['NumberOfVisit'].append(number_visits.text)

    # 로그 만들기
    log_count += 1
    if log_count > 0 and log_count % 20 == 0:
        print(log_count, end= " >>> ")
print("End")

print(review_data)
```

```python
# 데이터프레임 만들기
df_reviews = pd.DataFrame(review_data)

# .csv파일로 저장
df_reviews.to_csv("./shilla_hotel_buffet_review_original.csv")
```

### STEP 2. 계획 설정

1. 전체 함수 이름 결정: `get_review(url)`
2. 덩어리별로 분류:
	- 크롬 창 열고 url 접속하기: `open_url(url)`, output: `driver`
	- 더보기 버튼을 눌러 총 리뷰 갯수 구하기: `count_reviews(driver)`, output: `rows, cnt`
	- 리뷰 데이터를 추출하기: `crawling_reviews(rows, cnt)`, output: `review_data`

### STEP 3. 최종 코드 정리

```python
# Function 정리
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.common.actions.action_builder import ActionBuilder
from selenium.webdriver.common.actions.mouse_button import MouseButton
from selenium.webdriver import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import pandas as pd
```

```python
# 이번에 쓰이는 Functions
def open_url(url):

    """크롬 창을 열고 url에 접속하는 함수"""

    # 크롬창 열기
    options = Options()
    driver = webdriver.Chrome(options = options)

    # 창모드 전체화면으로 크기 늘리기
    driver.maximize_window()

    # 로딩시간: 페이지 로딩
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'body')))

    # 네이버 리뷰 주소 접속하기
    driver.get(url)

    # 로딩시간: 페이지 로딩
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'body')))
    return driver

def count_reviews(driver):

    """더보기 버튼을 통해 구하고자 하는 리뷰 갯수의 총 갯수를 구하는 함수"""

    for num_reviews in range(19):
        driver.find_element(By.CLASS_NAME, 'fvwqf').click()
        time.sleep(1)
    rows = driver.find_elements(By.CLASS_NAME, 'owAeM')

    # rows의 개수를 세어 for문을 돌린다.
    cnt = len(rows)
    print("총 리뷰 개수:", cnt)
    return rows, cnt

def crawling_reviews(rows, cnt):

    """리뷰 데이터를 추출하는 함수"""

    # 데이터 받을 빈 딕셔너리
    review_data = {"UserID":[],"Review_Text":[],"Date":[], "NumberOfVisit":[]}

    # 리뷰 추출하기
    log_count = 0

    print("START", end = " >>> ")
    for i in range(cnt):
        # 리뷰 내용 더보기 버튼이 없는 리뷰들 예외구문
        try:
            rows[i].find_element(By.CLASS_NAME, 'Ky28p').click()
        except:
            pass

        user_id = rows[i].find_element(By.CLASS_NAME, 'qgLL3')
        review_text = rows[i].find_element(By.CLASS_NAME, 'zPfVt')
        number_visits = rows[i].find_elements(By.CLASS_NAME, 'CKUdu')[1]
        visit_date = rows[i].find_elements(By.CLASS_NAME, 'CKUdu')[0].find_elements(By.CLASS_NAME, 'place_blind')[1]

        review_data['UserID'].append(user_id.text)
        review_data['Review_Text'].append(review_text.text)
        review_data['Date'].append(visit_date.text)
        review_data['NumberOfVisit'].append(number_visits.text)

        # 로그 만들기
        log_count += 1
        if log_count > 0 and log_count % 20 == 0:
            print(log_count, end= " >>> ")
    print("End")
    return review_data
```

```python
# 메인 함수
def get_review(url):

    """메인 함수"""

    # 크롬 창 열기
    print(f"크롬 창을 열고 있습니다.", end=" ")
    driver = open_url(url)
    print()

    title = driver.find_element(By.CLASS_NAME, 'GHAhO').text

    # 총 리뷰 개수 구하기
    print("'{0}'의 리뷰를 가지고 오는 중입니다.".format(title))
    rows, cnt = count_reviews(driver)

    # 딕셔너리 만들기
    review_data = crawling_reviews(rows,cnt)

    # 데이터프레임 만들기
    print("데이터프레임으로 변환 중입니다.",end=" ")
    df_reviews = pd.DataFrame(review_data)
    print("... 완료!")

    # .csv파일로 저장
    df_reviews.to_csv("./shilla_hotel_buffet_review_original.csv")
    driver.quit()
    return df_reviews
```

---
## 2. 데이터 전처리

>[!reference] Reference
>[동국대 텍스트 전처리](http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%A0%84%EC%B2%98%EB%A6%AC.html)
>[한국어 불용어 처리 1](https://bab2min.tistory.com/544)
>[한국어 불용어 처리 2](https://www.ranks.nl/stopwords/korean)
>[위키독스](https://wikidocs.net/92961)
>[한국어 텍스트 전처리](https://pinopino.tistory.com/entry/%ED%95%9C%EA%B5%AD%EC%96%B4-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC)
>[Github정리](https://gist.github.com/kse0202/9d3d8d519170064cefdd12fcb718afa0)
>[이모티콘 제거](https://codingdog.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-emoji-%ED%8C%A8%ED%82%A4%EC%A7%80%EC%9D%98-replaceemoji%EB%A1%9C-%EC%9D%B4%EB%AA%A8%EC%A7%80%EB%A5%BC-%EC%A0%9C%EA%B1%B0%ED%95%B4-%EB%B4%85%EC%8B%9C%EB%8B%A4)
>[이모티콘/특수문자 제거](https://velog.io/@highway92/%ED%85%8D%EC%8A%A4%ED%8A%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC)

- <span style="color: #000000; background-color:#ffd801;">데이터전처리 방법은 작성자 마음이다.</span>

### 데이터 전처리시 생각해야하는 것

1. 특수문자, 초성기호 등 제거
	- `re.sub()`함수 쓰기
2. 문장의 길이
	- 문장의 길이 이상치를 정한 다음 이를 넘기거나 혹은 이에 준하지 못하는 문장은 제거
3. 맞춤법 /  띄어쓰기
	- `pyhanspell` / `pykospacing` 사용
	- 시간이 오래 걸린다는 단점